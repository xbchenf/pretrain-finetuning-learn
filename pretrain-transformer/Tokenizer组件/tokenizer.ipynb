{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer åŸºæœ¬ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å­¦æœ¯èµ„æºåŠ é€Ÿ\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b710ddd0e1404e8bf0c176e7e3749c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08b9f68179a40cc918c3bacdc058040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409cd77565f94f7da8f9902d2d07805b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9eb4a4e1add40b5b8e849c461d66cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒçš„Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# å¾…å¤„ç†çš„æ–‡æœ¬\n",
    "text = \"Transformers are the core of modern NLP tasks.\"\n",
    "\n",
    "# ä½¿ç”¨Tokenizerè¿›è¡Œç¼–ç \n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# è®¿é—®ç¼–ç ç»“æœ\n",
    "input_ids = encoded_input['input_ids']\n",
    "attention_mask = encoded_input['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"åƒè‘¡è„ä¸åè‘¡è„çš®!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 åŠ è½½ä¸ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»HuggingFaceåŠ è½½ï¼Œè¾“å…¥æ¨¡å‹åç§°ï¼Œå³å¯åŠ è½½å¯¹äºçš„åˆ†è¯å™¨\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta_tokenizer/tokenizer_config.json',\n",
       " './roberta_tokenizer/special_tokens_map.json',\n",
       " './roberta_tokenizer/vocab.txt',\n",
       " './roberta_tokenizer/added_tokens.json',\n",
       " './roberta_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer ä¿å­˜åˆ°æœ¬åœ°\n",
    "tokenizer.save_pretrained(\"./roberta_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»æœ¬åœ°åŠ è½½tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer/\")\n",
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 å¥å­åˆ†è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['åƒ', 'è‘¡', 'è„', 'ä¸', 'å', 'è‘¡', 'è„', 'çš®', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sen)\n",
    "tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 æŸ¥çœ‹è¯å…¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##å‰': 14406,\n",
       " '##è˜†': 19035,\n",
       " 'åŸ': 1412,\n",
       " '##ç…Œ': 17259,\n",
       " 'æ‰‹': 2797,\n",
       " 'ã«': 558,\n",
       " '##è‚‹': 18547,\n",
       " 'è©±': 6282,\n",
       " '##çˆ†': 17312,\n",
       " 'by': 8120,\n",
       " '##eep': 12293,\n",
       " 'm1': 10211,\n",
       " 'éœœ': 7458,\n",
       " 'time': 8759,\n",
       " 'è¼¾': 6747,\n",
       " '##æ€…': 15637,\n",
       " '##ç¯¡': 18127,\n",
       " 'neo': 12169,\n",
       " '##è½': 18875,\n",
       " 'ieee': 12272,\n",
       " 'è´²': 6584,\n",
       " '##å™¢': 14745,\n",
       " '##è½©': 19816,\n",
       " '##å—–': 14683,\n",
       " 'å€': 945,\n",
       " '##shi': 9655,\n",
       " '##media': 10970,\n",
       " 'gtx': 11069,\n",
       " '##æ²‚': 16809,\n",
       " 'æ‹¢': 2879,\n",
       " 'è„˜': 5557,\n",
       " 'ä¾„': 888,\n",
       " '##æ‰‰': 15853,\n",
       " 'åˆƒ': 1145,\n",
       " '##á„†': 13459,\n",
       " 'ï¼¾': 8048,\n",
       " '##æ“˜': 16143,\n",
       " '##é­…': 20848,\n",
       " '##æ™': 16299,\n",
       " 'âŒ’': 404,\n",
       " '##bo': 8820,\n",
       " '##é‚¨': 19988,\n",
       " '##é›…': 20471,\n",
       " 'notes': 13165,\n",
       " 'è¸Ÿ': 6676,\n",
       " '##è‰º': 18743,\n",
       " '##æ»': 16008,\n",
       " '##ç»©': 18384,\n",
       " 'äº': 765,\n",
       " '543': 11895,\n",
       " 'eq': 11601,\n",
       " 'pure': 13179,\n",
       " 'æº': 2982,\n",
       " '##è–': 18526,\n",
       " '##çˆº': 17327,\n",
       " '##ï¼': 21082,\n",
       " 'â†': 368,\n",
       " 'èœ±': 6061,\n",
       " 'è‚„': 5485,\n",
       " 'ç•™': 4522,\n",
       " 'member': 11120,\n",
       " '##men': 11839,\n",
       " '##å€¼': 14023,\n",
       " '##æ¤°': 16553,\n",
       " 'è‚´': 5510,\n",
       " 'ç¶': 5193,\n",
       " 'ç—ˆ': 4569,\n",
       " 'åˆ': 970,\n",
       " '##åµ': 14037,\n",
       " '0t': 10691,\n",
       " '##çµµ': 18246,\n",
       " 'ç±¤': 5097,\n",
       " '##lot': 10580,\n",
       " 'å§': 1309,\n",
       " '##åŠ³': 14284,\n",
       " '##å‰½': 14260,\n",
       " '##å¤©': 14978,\n",
       " 'èœš': 6056,\n",
       " '##çª©': 18036,\n",
       " '##ã‚¨': 13682,\n",
       " 'å™—': 1684,\n",
       " '##ç¼™': 18415,\n",
       " 'ã†': 666,\n",
       " '##è‰¾': 18744,\n",
       " 'æ“˜': 3086,\n",
       " '##è¨Š': 19301,\n",
       " 'è‡': 5823,\n",
       " '##æ’»': 16128,\n",
       " '##ç·¬': 18285,\n",
       " '##å“„': 14560,\n",
       " 'è®ª': 6376,\n",
       " '##è‡†': 18678,\n",
       " 'é²¸': 7841,\n",
       " '##æ–¡': 16221,\n",
       " '##ace': 10026,\n",
       " 'æ­£': 3633,\n",
       " 'å»': 1431,\n",
       " '##å€': 14827,\n",
       " '##ç¯': 17185,\n",
       " '##ç—´': 17647,\n",
       " 'å‡±': 1134,\n",
       " 'èª': 6295,\n",
       " '##ç²®': 18174,\n",
       " '##è„«': 18619,\n",
       " '##è¯': 19470,\n",
       " '##é™Œ': 20416,\n",
       " 'é­·': 7799,\n",
       " 'wang': 9660,\n",
       " 'è©°': 6281,\n",
       " 'æ¤': 3491,\n",
       " '##ç Œ': 17831,\n",
       " '##è² ': 19568,\n",
       " '##å··': 15407,\n",
       " '##sp': 10367,\n",
       " 'ç¸': 5237,\n",
       " 'è©•': 6268,\n",
       " 'news': 8501,\n",
       " 'ç¬': 4126,\n",
       " '##ç¼®': 18427,\n",
       " 'å“': 1501,\n",
       " 'ç°‡': 5077,\n",
       " 'è¸ª': 6679,\n",
       " 'ç›–': 4667,\n",
       " '##å¢': 14422,\n",
       " '##ç–Ÿ': 17606,\n",
       " '##æª³': 16656,\n",
       " 'æ­‡': 3623,\n",
       " '112': 9017,\n",
       " '##ä¸¼': 13770,\n",
       " 'æŒ ': 2912,\n",
       " 'ç©º': 4958,\n",
       " 'èˆŸ': 5660,\n",
       " 'è²': 6509,\n",
       " 'è´«': 6577,\n",
       " '349': 12110,\n",
       " '##ã‚†': 13676,\n",
       " 'rights': 9615,\n",
       " '##æ¼²': 17096,\n",
       " 'è£±': 6177,\n",
       " 'âˆ®': 387,\n",
       " '##ç”µ': 17567,\n",
       " 'æ”™': 3107,\n",
       " '##çŸ¯': 17823,\n",
       " '##è¢ª': 19214,\n",
       " '##é™µ': 20434,\n",
       " 'é¦®': 7681,\n",
       " 'é¸Ÿ': 7881,\n",
       " 'apr': 9011,\n",
       " 'idc': 9617,\n",
       " '##icon': 12829,\n",
       " '##Ù„': 13435,\n",
       " '##éŒš': 20147,\n",
       " '##é¬¥': 20841,\n",
       " 'æ¿›': 4088,\n",
       " 'special': 9969,\n",
       " '##è³‘': 19596,\n",
       " 'å—š': 1627,\n",
       " 'éº': 7928,\n",
       " 'è¿™': 6821,\n",
       " 'èŸ ': 6098,\n",
       " '##ä¹': 13782,\n",
       " 'ç±': 5093,\n",
       " 'woshipm': 9712,\n",
       " '##ã„Ÿ': 13718,\n",
       " '##æ·…': 16954,\n",
       " 'è ': 6075,\n",
       " '##ãªã‚Š': 11592,\n",
       " 'ç—‚': 4566,\n",
       " '2020': 8439,\n",
       " 'æ‰«': 2812,\n",
       " 'è™': 5988,\n",
       " '##å†¯': 14158,\n",
       " '##ç•ª': 17585,\n",
       " '##æ‚±': 15706,\n",
       " '##è“¼': 18967,\n",
       " '##é¥': 20162,\n",
       " 'ç‚®': 4152,\n",
       " '##ction': 9116,\n",
       " 'é©¢': 7714,\n",
       " '##ä½Ÿ': 13928,\n",
       " 'ç‚€': 4137,\n",
       " '##ä¸¾': 13772,\n",
       " 'ç± ': 5096,\n",
       " '##å¦ƒ': 15021,\n",
       " 'èª¹': 6308,\n",
       " '##ors': 10903,\n",
       " '##æ±›': 16790,\n",
       " '##èµ…': 19656,\n",
       " 'wap': 9530,\n",
       " '##é”¹': 20303,\n",
       " '##70': 8740,\n",
       " '##çŒœ': 17396,\n",
       " 'å¨©': 2030,\n",
       " 'lte': 8987,\n",
       " '##home': 10479,\n",
       " 'ï½': 8080,\n",
       " '6500': 11247,\n",
       " '2a': 11646,\n",
       " 'self': 12178,\n",
       " 'eps': 9629,\n",
       " '3800': 11433,\n",
       " '[unused65]': 65,\n",
       " 'é–‘': 7277,\n",
       " '##kw': 10446,\n",
       " 'è•ª': 5940,\n",
       " 'cafe2017': 8986,\n",
       " '##å¸‘': 15420,\n",
       " '##è©³': 19341,\n",
       " '##éŠ': 20168,\n",
       " '##ã‚ˆ': 9427,\n",
       " '925': 10711,\n",
       " 'è‰‡': 5673,\n",
       " 'é–’': 7278,\n",
       " 'åŒ¯': 1274,\n",
       " '##å²±': 15333,\n",
       " '##æ¿¡': 17148,\n",
       " 'éœ–': 7457,\n",
       " '##åˆ': 14343,\n",
       " 'æ¯—': 3685,\n",
       " 'æ ƒ': 3400,\n",
       " 'åƒ‘': 1009,\n",
       " '8cm': 12237,\n",
       " 'è½Ÿ': 6755,\n",
       " 'éŸµ': 7510,\n",
       " 'å‘¢': 1450,\n",
       " 'è´º': 6590,\n",
       " 'åŸ”': 1815,\n",
       " '##æŸµ': 16453,\n",
       " 'é‚£': 6929,\n",
       " '383': 12510,\n",
       " 'è²': 5476,\n",
       " '##dget': 11857,\n",
       " 'atm': 8366,\n",
       " '##æ¢†': 16507,\n",
       " 'ç±Ÿ': 5095,\n",
       " 'èœ´': 6062,\n",
       " 'dear': 11694,\n",
       " '##ç›¸': 17742,\n",
       " '##å¯¥': 15235,\n",
       " '##é•œ': 20319,\n",
       " 'èŠ«': 5704,\n",
       " '413': 12561,\n",
       " 'éª—': 7745,\n",
       " '26': 8153,\n",
       " '##cord': 12291,\n",
       " 'é£•': 7602,\n",
       " '##ç¥': 17911,\n",
       " '##æ¾±': 17134,\n",
       " 'æ˜‡': 3205,\n",
       " 'cio': 9351,\n",
       " '##ç–': 17433,\n",
       " '##å‘‹': 14498,\n",
       " '##ç‰›': 17338,\n",
       " '##èœ‡': 19104,\n",
       " '##ç´³': 18227,\n",
       " 'fedora': 11577,\n",
       " 'è´ˆ': 6557,\n",
       " '##è‰˜': 18732,\n",
       " '##ç—˜': 17633,\n",
       " 'yy': 9453,\n",
       " '##åŒ±': 14332,\n",
       " 'tai': 13242,\n",
       " '##æ¿›': 17145,\n",
       " '%': 110,\n",
       " 'æ¾§': 4076,\n",
       " 'ç´§': 5165,\n",
       " '##ä¿‘': 13977,\n",
       " '##éƒ­': 20015,\n",
       " '##è™½': 19063,\n",
       " '##çˆ·': 17324,\n",
       " '##free': 13287,\n",
       " 'ç¿»': 5436,\n",
       " 'å’': 1464,\n",
       " '##ï½ƒ': 10675,\n",
       " 'today': 11262,\n",
       " '##áµƒ': 13489,\n",
       " 'bot': 11825,\n",
       " '##æ–¼': 16233,\n",
       " 'april': 9557,\n",
       " '##æ™': 16291,\n",
       " '##è€¸': 18515,\n",
       " '##èŸ»': 19159,\n",
       " 'ram': 9270,\n",
       " 'å±Š': 2237,\n",
       " '##æ¬': 16078,\n",
       " '##èŠ¦': 18758,\n",
       " '##é¸': 19965,\n",
       " '##åŠ£': 14276,\n",
       " '019': 13146,\n",
       " 'ã•': 546,\n",
       " 'é»œ': 7951,\n",
       " 'á…´': 319,\n",
       " '##ä¾„': 13945,\n",
       " 'æ±•': 3730,\n",
       " '##æ€¥': 15650,\n",
       " '##me': 8505,\n",
       " '##çš„': 17695,\n",
       " '625': 12218,\n",
       " 'miacare': 11918,\n",
       " '##è„‘': 18611,\n",
       " '##æª': 15675,\n",
       " 'é“': 7196,\n",
       " '1968': 9045,\n",
       " 'è¢’': 6152,\n",
       " '##é³': 20903,\n",
       " 'ä¸›': 690,\n",
       " '##æ‹¢': 15936,\n",
       " '##æ±€': 16779,\n",
       " 'éœ‡': 7448,\n",
       " '##ã‡': 13669,\n",
       " '##æ»¬': 17071,\n",
       " 'dm': 10442,\n",
       " 'çœ™': 4694,\n",
       " 'ä¹˜': 733,\n",
       " '##å…': 14095,\n",
       " 'æ™š': 3241,\n",
       " 'é‡': 6878,\n",
       " 'ç‡‰': 4237,\n",
       " 'body': 9867,\n",
       " 'æ³«': 3802,\n",
       " 'ï¾—': 8095,\n",
       " '##ein': 11858,\n",
       " 'boost': 11986,\n",
       " '##dge': 12025,\n",
       " '##tive': 9741,\n",
       " 'north': 10744,\n",
       " '5c': 13025,\n",
       " 'æ¡¥': 3441,\n",
       " '##å†€': 14135,\n",
       " '##ias': 12803,\n",
       " 'åŒ': 1398,\n",
       " '##åˆ’': 14210,\n",
       " '##æ¸”': 16991,\n",
       " 'ç»®': 5331,\n",
       " '##ç•¥': 17583,\n",
       " 'å‘ˆ': 1439,\n",
       " 'æˆ': 2956,\n",
       " 'mama': 13186,\n",
       " 'æº–': 3976,\n",
       " 'é½£': 7974,\n",
       " 'frm': 11794,\n",
       " '##lter': 12171,\n",
       " '##á†·': 13484,\n",
       " 'tcp': 9901,\n",
       " 'ssd': 9004,\n",
       " '##å½“': 15553,\n",
       " '##ç•œ': 17580,\n",
       " 'å±¤': 2251,\n",
       " '##ç¾': 18458,\n",
       " '##ç¶': 17188,\n",
       " 'æœ€': 3297,\n",
       " 'ç§Ÿ': 4909,\n",
       " '##è´±': 19640,\n",
       " 'æµ‹': 3844,\n",
       " 'Â»': 188,\n",
       " 'å‚¥': 995,\n",
       " 'é³': 7850,\n",
       " '##å¦³': 15043,\n",
       " '##Î»': 13389,\n",
       " 'cell': 11490,\n",
       " '##ç­': 18083,\n",
       " '##ly': 8436,\n",
       " '##è€¨': 18511,\n",
       " '##è©•': 19325,\n",
       " '##é‚¢': 19985,\n",
       " '##éª†': 20793,\n",
       " '##è¡„': 19175,\n",
       " 'ç…': 4414,\n",
       " 'ç¶': 4131,\n",
       " 'é›': 7421,\n",
       " '##éª¸': 20817,\n",
       " '##mate': 12125,\n",
       " '##ï½‹': 10981,\n",
       " '250': 8401,\n",
       " '##å±‹': 15295,\n",
       " 'åªš': 2055,\n",
       " 'ç¢´': 4824,\n",
       " 'è€•': 5449,\n",
       " 'è„±': 5564,\n",
       " 'é¦€': 7663,\n",
       " 'à¸‡': 277,\n",
       " '##ways': 11672,\n",
       " '##æ‰¯': 15873,\n",
       " '##æ‹œ': 15933,\n",
       " 'cn': 8274,\n",
       " '##æ§›': 16603,\n",
       " 'è’¿': 5896,\n",
       " 'ï½²': 8088,\n",
       " '##æ‘Š': 16090,\n",
       " '##çª': 18017,\n",
       " '##ï¹': 21067,\n",
       " '##ãƒ³ã‚¯': 9262,\n",
       " 'mtv': 11529,\n",
       " '##â—†': 10497,\n",
       " '##700': 11551,\n",
       " '##ä½š': 13923,\n",
       " 'pt': 10791,\n",
       " 'vga': 13140,\n",
       " 'é¹ˆ': 7901,\n",
       " 'äº›': 763,\n",
       " '[unused82]': 82,\n",
       " '##ã¯': 8319,\n",
       " '##lli': 13169,\n",
       " '##æŠš': 15893,\n",
       " 'ktv': 8894,\n",
       " '##ration': 11103,\n",
       " 'æ½®': 4060,\n",
       " 'ç›¸': 4685,\n",
       " 'inparadise': 12484,\n",
       " 'å››': 1724,\n",
       " '##è’': 18859,\n",
       " 'æ»': 4005,\n",
       " 'ä¾–': 895,\n",
       " '##æ¾„': 17124,\n",
       " 'l1': 12421,\n",
       " 'cool1': 12032,\n",
       " 'èµŒ': 6603,\n",
       " '##å½Œ': 15550,\n",
       " 'æ»„': 3993,\n",
       " 'å“©': 1524,\n",
       " 'å¾': 2528,\n",
       " 'pony': 8365,\n",
       " '##é†«': 20072,\n",
       " 'ã„†': 648,\n",
       " '##ã‘ã¨': 10095,\n",
       " '##è‚“': 18550,\n",
       " '##èˆµ': 18723,\n",
       " 'å¦£': 1978,\n",
       " '##int': 9824,\n",
       " '##é˜€': 20379,\n",
       " 'æ†‘': 2731,\n",
       " 'çª¨': 4978,\n",
       " '##æƒ ': 15726,\n",
       " '##æ¼¢': 17088,\n",
       " 'å¨›': 2024,\n",
       " 'æŠ„': 2826,\n",
       " '##cr': 13129,\n",
       " '##é”º': 20304,\n",
       " '##å“¥': 14577,\n",
       " 'ç»¥': 5324,\n",
       " 'å…¶': 1071,\n",
       " 'ç¼ˆ': 5350,\n",
       " 'å»–': 2445,\n",
       " 'å„¿': 1036,\n",
       " 'æ¸™': 3936,\n",
       " 'é¯½': 7811,\n",
       " 'å‚¬': 998,\n",
       " 'å…”': 1052,\n",
       " '##å¡': 14362,\n",
       " 'é“¸': 7214,\n",
       " 'å¿œ': 2565,\n",
       " 'é‚‚': 6915,\n",
       " 'é€': 6861,\n",
       " '##ä¿': 13975,\n",
       " 'å¦¹': 1987,\n",
       " 'æ ': 3408,\n",
       " '##å§š': 15058,\n",
       " 'æ': 2607,\n",
       " '##Ë': 13375,\n",
       " '##é ‚': 20572,\n",
       " '##è›¾': 19099,\n",
       " 'åˆ': 1348,\n",
       " 'Ğ¼': 244,\n",
       " 'å™': 1360,\n",
       " 'æ­·': 3644,\n",
       " 'ï¾™': 8096,\n",
       " 'work': 10782,\n",
       " 'ç²¿': 5126,\n",
       " 'ç­Š': 5024,\n",
       " 'watch': 9114,\n",
       " 'jquery': 10035,\n",
       " 'é“œ': 7198,\n",
       " '##ose': 10936,\n",
       " 'å°»': 2224,\n",
       " 'æº±': 3986,\n",
       " 'é œ': 7527,\n",
       " '##å²˜': 15324,\n",
       " 'å¼“': 2469,\n",
       " 'ç„œ': 4191,\n",
       " '##man': 8490,\n",
       " '##hn': 11781,\n",
       " '##å¾©': 15598,\n",
       " '##æ†¨': 15793,\n",
       " '##æ£ ': 16535,\n",
       " '##æ¿‘': 17141,\n",
       " 'è«·': 6327,\n",
       " '##çœ¼': 17763,\n",
       " '##è€•': 18506,\n",
       " '1953': 9268,\n",
       " 'é£¼': 7615,\n",
       " '##è£•': 19225,\n",
       " 'ï¼’ï¼': 10327,\n",
       " 'è‚º': 5511,\n",
       " 'google': 8190,\n",
       " 'è¿¢': 6827,\n",
       " '##tes': 9420,\n",
       " '##é„‰': 20022,\n",
       " 'å½•': 2497,\n",
       " '##å¦“': 15029,\n",
       " 'ç‘•': 4442,\n",
       " '##å¸½': 15441,\n",
       " 'æ—¶': 3198,\n",
       " '##æƒš': 15723,\n",
       " '##bs': 9071,\n",
       " '58': 8255,\n",
       " '##ã†': 8981,\n",
       " '##æˆ–': 15829,\n",
       " 'alexander': 11733,\n",
       " '##æ': 15664,\n",
       " '##è´“': 19618,\n",
       " '##26': 8756,\n",
       " '##ã‚’ã“': 12335,\n",
       " '##è¥¬': 19259,\n",
       " 'ç¾ˆ': 5398,\n",
       " 'å†²': 1103,\n",
       " 'è¢‹': 6150,\n",
       " 'è®·': 6386,\n",
       " 'é…': 6986,\n",
       " 'æŸš': 3384,\n",
       " '##æ‚¨': 15701,\n",
       " '##æ¶¸': 16949,\n",
       " 'ãƒ': 624,\n",
       " '##æ…°': 15777,\n",
       " '##æ»…': 17051,\n",
       " '##çŒ': 17397,\n",
       " 'é‡¦': 7038,\n",
       " '##å€º': 14022,\n",
       " '##æ‚': 16065,\n",
       " 'â”€': 427,\n",
       " 'é‘Š': 7140,\n",
       " 'å©ª': 2046,\n",
       " 'ï½œ': 8078,\n",
       " '##ã‚¤ãƒˆ': 10516,\n",
       " 'çœ¨': 4699,\n",
       " 'loading': 10878,\n",
       " '##ç¼¸': 18431,\n",
       " 'æ³ ': 3795,\n",
       " '##è¯': 19462,\n",
       " '##è¸Œ': 19728,\n",
       " '##é–': 20333,\n",
       " 'åŸ¹': 1824,\n",
       " '##ç‡œ': 17301,\n",
       " '3500': 9252,\n",
       " 'å¥': 1368,\n",
       " 'ç…½': 4218,\n",
       " '##å…¨': 14116,\n",
       " '20': 8113,\n",
       " '##age': 9103,\n",
       " '##æ¸´': 17008,\n",
       " '##è•': 18987,\n",
       " '##éµ': 20164,\n",
       " '##èƒ¤': 18587,\n",
       " 'èŠ': 5694,\n",
       " '##å’': 14350,\n",
       " 'elle': 11593,\n",
       " '##æ‘¹': 16101,\n",
       " 'ï¼ˆ': 8020,\n",
       " 'title': 9956,\n",
       " '##ç–®': 17612,\n",
       " '##ç§ƒ': 17958,\n",
       " 'jpeg': 11985,\n",
       " 'çªœ': 4972,\n",
       " '##è²¢': 19570,\n",
       " '##éš…': 20440,\n",
       " 'æ•ˆ': 3126,\n",
       " '##å®´': 15212,\n",
       " '161': 9608,\n",
       " '##.': 13330,\n",
       " 'å§—': 2000,\n",
       " 'css': 8935,\n",
       " 'ç¨ ': 4932,\n",
       " 'program': 11738,\n",
       " '##å˜': 14387,\n",
       " '##è¡²': 19197,\n",
       " 'å†‡': 1081,\n",
       " '##dom': 11290,\n",
       " 'ï¼': 8025,\n",
       " '##è‡¥': 18686,\n",
       " 'claire': 9753,\n",
       " '##èœ´': 19119,\n",
       " 'Â±': 181,\n",
       " 'çƒƒ': 4163,\n",
       " '##l': 8178,\n",
       " 'è°Ÿ': 6467,\n",
       " 'ç±®': 5099,\n",
       " '12345678910': 9363,\n",
       " 'å–‰': 1590,\n",
       " '##è¹´': 19760,\n",
       " 'æ': 2933,\n",
       " 'å²­': 2275,\n",
       " 'æ³½': 3813,\n",
       " '##âˆ½': 13541,\n",
       " 'å¾´': 2546,\n",
       " 'é“¢': 7202,\n",
       " '##å“”': 14573,\n",
       " 'ãƒ¼': 645,\n",
       " 'lost': 12593,\n",
       " 'è¨': 6252,\n",
       " 'ç˜«': 4611,\n",
       " '##åŒ': 14320,\n",
       " 'è´': 5478,\n",
       " 'ling': 10061,\n",
       " 'eyes': 12909,\n",
       " '##ç§˜': 17965,\n",
       " '##á…´': 13483,\n",
       " 'å„²': 1033,\n",
       " 'limited': 10424,\n",
       " '##å²³': 15334,\n",
       " 'æ°¸': 3719,\n",
       " 'i3': 12224,\n",
       " 'ç­ ': 5035,\n",
       " 'å˜œ': 1659,\n",
       " '##cky': 11216,\n",
       " 'è­˜': 6352,\n",
       " 'è³¢': 6545,\n",
       " '##ä»Š': 13848,\n",
       " 'oem': 9945,\n",
       " '3000': 8283,\n",
       " 'vs': 8349,\n",
       " '##è°¢': 19525,\n",
       " 'å€¬': 962,\n",
       " 'æŠ¤': 2844,\n",
       " 'ç§ƒ': 4901,\n",
       " '[unused30]': 30,\n",
       " '##ç…': 17265,\n",
       " '106': 8438,\n",
       " '##ã¨': 8322,\n",
       " 'av': 8375,\n",
       " '##å­œ': 15161,\n",
       " 'è³Š': 6538,\n",
       " 'á…¦': 308,\n",
       " '##æœ±': 16376,\n",
       " '##è¿ˆ': 19872,\n",
       " '##ç“¶': 17543,\n",
       " '##aka': 12417,\n",
       " '##å–†': 14645,\n",
       " 'å½—': 2498,\n",
       " 'å¦³': 1986,\n",
       " '##â–¡': 13606,\n",
       " '##how': 13132,\n",
       " 'å–¬': 1605,\n",
       " 'ç¨œ': 4929,\n",
       " '##èœ˜': 19112,\n",
       " 'â†“': 371,\n",
       " 'single': 12148,\n",
       " 'è³': 6089,\n",
       " '##tory': 12608,\n",
       " '##é¥': 20696,\n",
       " 'é»›': 7950,\n",
       " 'ä»²': 815,\n",
       " 'ç¼•': 5355,\n",
       " 'é ': 6895,\n",
       " '1990': 8431,\n",
       " '232': 9863,\n",
       " 'æ²–': 3762,\n",
       " '##æ¢': 16505,\n",
       " '##ç„¦': 17250,\n",
       " '\\\\': 139,\n",
       " '##åµ¬': 15377,\n",
       " 'ç¹½': 5263,\n",
       " '##eme': 12538,\n",
       " '##å±¿': 15314,\n",
       " '##éœ': 20510,\n",
       " 'å±': 2230,\n",
       " '##æ ‰': 16462,\n",
       " '##æ¹˜': 17017,\n",
       " 'yumi': 11697,\n",
       " 'weeks': 11973,\n",
       " '##åŠ­': 14281,\n",
       " 'xp': 8766,\n",
       " 'ç²³': 5120,\n",
       " '##net': 8914,\n",
       " 'ide': 11319,\n",
       " '##ç›²': 17740,\n",
       " '##ä¸¶': 13765,\n",
       " 'æ™®': 3249,\n",
       " '##å–‹': 14649,\n",
       " 'é¢±': 7593,\n",
       " '##æºº': 17046,\n",
       " '##é§': 20741,\n",
       " 'è„›': 5559,\n",
       " '##å': 14346,\n",
       " '##73': 9148,\n",
       " '##ç½”': 18439,\n",
       " 'â–Œâ™¥': 9601,\n",
       " 'èƒ': 5516,\n",
       " '##èš': 19066,\n",
       " '##èŠ': 18751,\n",
       " '##çªŸ': 18031,\n",
       " '##è¯¾': 19497,\n",
       " '##è»': 18851,\n",
       " '##ç¹¼': 18319,\n",
       " '##é': 20170,\n",
       " 'æ¸›': 3938,\n",
       " 'å£²': 1899,\n",
       " 'ã—': 547,\n",
       " 'æ¹Š': 3957,\n",
       " 'è®¿': 6393,\n",
       " '##ãƒ¢': 13694,\n",
       " 'ff': 12388,\n",
       " '##x2': 12505,\n",
       " '##ä¸“': 13740,\n",
       " '##æ£²': 16540,\n",
       " '##è²§': 19571,\n",
       " 'è¡¢': 6131,\n",
       " '##é”‘': 20287,\n",
       " 'database': 12435,\n",
       " 'å•§': 1569,\n",
       " 'å¤®': 1925,\n",
       " 'good': 9005,\n",
       " 'canada': 12947,\n",
       " '##ç•…': 17574,\n",
       " 'æ‰­': 2814,\n",
       " '##èŠ®': 18764,\n",
       " '##é¸£': 20942,\n",
       " 'é§…': 7686,\n",
       " 'æª¢': 3596,\n",
       " '##c': 8177,\n",
       " 'ç€‹': 4103,\n",
       " '34': 8229,\n",
       " 'may': 8480,\n",
       " '##å¥¹': 15018,\n",
       " '##æ‹¾': 15953,\n",
       " '##eng': 9995,\n",
       " '##èŠ¸': 18769,\n",
       " '##åˆŠ': 14206,\n",
       " '##è¯»': 19495,\n",
       " 'ä¿': 919,\n",
       " '##è¶µ': 19698,\n",
       " 'ä¿¯': 935,\n",
       " 'å•»': 1581,\n",
       " '##dden': 13109,\n",
       " '##é›': 20487,\n",
       " '##é—Š': 20352,\n",
       " 'å·²': 2347,\n",
       " 'å˜': 1330,\n",
       " 'å¿»': 2574,\n",
       " 'ï½': 8051,\n",
       " 'sense': 12647,\n",
       " '##å¿ª': 15627,\n",
       " 'åƒ': 1347,\n",
       " 'pixnet': 8191,\n",
       " '##cil': 11783,\n",
       " 'çŠ': 4301,\n",
       " '##ç½¹': 18452,\n",
       " '##point': 11112,\n",
       " '##ç›´': 17741,\n",
       " 'æ–—': 3159,\n",
       " '##é·—': 20932,\n",
       " 'æº': 3025,\n",
       " 'ç¨¹': 4939,\n",
       " 'å·½': 2352,\n",
       " 'nata': 10166,\n",
       " 'spf': 12598,\n",
       " 'ç˜€': 4595,\n",
       " 'Ù‡': 272,\n",
       " '##ç¥–': 17919,\n",
       " 'è®¾': 6392,\n",
       " '##ã»': 13672,\n",
       " 'ä¾': 892,\n",
       " 'æ¨': 3561,\n",
       " 'æ¹³': 3967,\n",
       " '##ç…Š': 17258,\n",
       " '##å·«': 15401,\n",
       " 'çœº': 4705,\n",
       " 'è«§': 6321,\n",
       " '##å': 14831,\n",
       " '##ç‘„': 17497,\n",
       " '##cs': 9761,\n",
       " 'ç­‘': 5029,\n",
       " '##æ—­': 16252,\n",
       " 'é': 7491,\n",
       " 'æŸ˜': 3383,\n",
       " '##ã‚·ãƒ£ãƒ³ãƒ«ã®': 11947,\n",
       " '##ã“ã¨ã‹': 10274,\n",
       " '##æ‰¿': 15881,\n",
       " 'è™½': 6006,\n",
       " '##å¨¶': 15091,\n",
       " 'è”½': 5929,\n",
       " 'é—†': 7293,\n",
       " '##å•°': 14631,\n",
       " '##çƒ¨': 17231,\n",
       " '##ç´€': 18202,\n",
       " 'å‚»': 1004,\n",
       " 'æ“': 3083,\n",
       " 'æ­': 3368,\n",
       " 'çš™': 4647,\n",
       " 'èƒ«': 5533,\n",
       " '366': 11949,\n",
       " '##ons': 9961,\n",
       " '##ets': 12198,\n",
       " '##è€½': 18517,\n",
       " 'r9': 12674,\n",
       " '##sy': 10178,\n",
       " '##cle': 11619,\n",
       " '##ssion': 12726,\n",
       " '##è™•': 19050,\n",
       " 'ç›': 4672,\n",
       " 'åš': 1780,\n",
       " '##è³½': 19612,\n",
       " '##h': 8199,\n",
       " 'å‡': 1125,\n",
       " '##è·': 19712,\n",
       " 'shop': 9926,\n",
       " 'ç©': 4381,\n",
       " '##ã‚«ãƒ¼': 10175,\n",
       " '##å…„': 14097,\n",
       " 'å€­': 963,\n",
       " '##æ³¾': 16871,\n",
       " 'æ“±': 3095,\n",
       " '5757': 12007,\n",
       " 'cisco': 11010,\n",
       " '##è´¿': 19651,\n",
       " '##å…§': 14115,\n",
       " 'å¨': 1417,\n",
       " 'å“‰': 1507,\n",
       " 'è¡®': 6138,\n",
       " 'food': 9579,\n",
       " 'ç‡': 4233,\n",
       " '##á†¸': 13485,\n",
       " 'æ ¼': 3419,\n",
       " '##ãƒ•ãƒˆ': 10868,\n",
       " '##å‡€': 14169,\n",
       " '##å¯©': 15239,\n",
       " '##æ‡¶': 15811,\n",
       " '##æŠ›': 15894,\n",
       " '##ç–š': 17604,\n",
       " '##è…•': 18637,\n",
       " '##é¤¨': 20688,\n",
       " 'è˜­': 5984,\n",
       " 'æ·¨': 3912,\n",
       " '##ric': 11748,\n",
       " '##æ¦¨': 16586,\n",
       " 'æƒ†': 2659,\n",
       " '309b': 9799,\n",
       " '##ã‚„ã‚Š': 11077,\n",
       " 'su': 11541,\n",
       " '##è½²': 19822,\n",
       " '##æ„Ÿ': 15754,\n",
       " '##é†’': 20065,\n",
       " 'â€ ': 339,\n",
       " 'ç ‚': 4773,\n",
       " 'è§†': 6228,\n",
       " 'éš': 7117,\n",
       " '##ford': 10283,\n",
       " 'bbe': 12517,\n",
       " '##è¼•': 19795,\n",
       " '##çµ¡': 18238,\n",
       " 'å¡¾': 1860,\n",
       " 'nike': 8702,\n",
       " 'ç¼¢': 5363,\n",
       " 'é‡': 7029,\n",
       " '##ova': 13067,\n",
       " 'é“': 7199,\n",
       " '##mi': 8625,\n",
       " '##æ†‹': 15785,\n",
       " '##æ²': 16034,\n",
       " '##æ': 15659,\n",
       " '1983': 8715,\n",
       " '##æ‘ˆ': 16089,\n",
       " 'á†¸': 325,\n",
       " 'æ¤': 3487,\n",
       " 'è°Œ': 6451,\n",
       " 'ï¼œ': 8040,\n",
       " 'è²½': 6529,\n",
       " '##ua': 9478,\n",
       " '##da': 8521,\n",
       " '##han': 9646,\n",
       " 'ğŸ”¥': 8103,\n",
       " 'fit': 11188,\n",
       " 'å­±': 2116,\n",
       " '##ess': 9685,\n",
       " '##á…®': 13479,\n",
       " '##ew': 10795,\n",
       " '##å’š': 14537,\n",
       " 'helpapp': 10609,\n",
       " 'æº': 3974,\n",
       " '##å§Š': 15049,\n",
       " '71': 8459,\n",
       " 'Ñ': 249,\n",
       " '##æ¥¨': 16566,\n",
       " 'cf1': 12327,\n",
       " '##é¡¾': 20617,\n",
       " 'éª': 7749,\n",
       " 'thai': 12967,\n",
       " 'â‘´': 415,\n",
       " 'ã¯ã„': 9781,\n",
       " '##ç›±': 17739,\n",
       " '##yo': 10222,\n",
       " 'çŠ·': 4308,\n",
       " 'è¯¸': 6436,\n",
       " '##é‡µ': 20097,\n",
       " '##è±': 19550,\n",
       " 'ä»–': 800,\n",
       " 'âœª': 502,\n",
       " 'ç—”': 4574,\n",
       " 'è™‘': 5991,\n",
       " '##å‘¨': 14510,\n",
       " '##æ¾': 17128,\n",
       " '##ç¼”': 18411,\n",
       " 'çŸ­': 4764,\n",
       " '<T>': 105,\n",
       " 'source': 9014,\n",
       " '##ç¼': 17494,\n",
       " 'èµ–': 6609,\n",
       " '##nk': 9705,\n",
       " '223': 10265,\n",
       " '##â—': 9037,\n",
       " '##è¥': 19254,\n",
       " '##ã€”': 13661,\n",
       " '##è›†': 19082,\n",
       " '##é”': 20285,\n",
       " 'è·³': 6663,\n",
       " '##â–‰': 13601,\n",
       " 'æ½': 3005,\n",
       " 'x5': 10871,\n",
       " 'ä»‡': 790,\n",
       " 'jayz': 11072,\n",
       " '52sykb': 12846,\n",
       " '##ç“œ': 17535,\n",
       " '##å¸ƒ': 15414,\n",
       " 'æ¯™': 3687,\n",
       " 'more': 8384,\n",
       " '6s': 9590,\n",
       " '##ston': 10229,\n",
       " '374': 11948,\n",
       " '##å½ˆ': 15549,\n",
       " '##éŸ¿': 20570,\n",
       " 'ç½': 4727,\n",
       " '##å«‘': 15124,\n",
       " 'é—¸': 7316,\n",
       " '##æ³“': 16847,\n",
       " 'f1': 9080,\n",
       " '##ç§½': 17977,\n",
       " 'æ›¸': 3292,\n",
       " 'ä¿±': 936,\n",
       " 'èµ': 5859,\n",
       " '##åœ§': 14818,\n",
       " 'æ™¤': 3245,\n",
       " 'ç¸½': 5244,\n",
       " '##å³¶': 15351,\n",
       " 'æ™Ÿ': 3244,\n",
       " '##ç…': 17788,\n",
       " '##ãƒãƒ¼': 10977,\n",
       " '144': 9494,\n",
       " 'å¥¶': 1959,\n",
       " '##é˜ˆ': 20385,\n",
       " '##é˜»': 20406,\n",
       " '##â‘¢': 13558,\n",
       " 'æŠŠ': 2828,\n",
       " 'é¦': 7664,\n",
       " 'amoled': 11307,\n",
       " 'éª·': 7759,\n",
       " 'tripadvisor': 8194,\n",
       " 'ç‰Œ': 4277,\n",
       " '##ted': 9255,\n",
       " '##ç«½': 18060,\n",
       " '##ç¸›': 18293,\n",
       " '##é»„': 20999,\n",
       " '##æ†«': 15795,\n",
       " '##mmy': 12137,\n",
       " 'æ±°': 3743,\n",
       " '790': 11793,\n",
       " 'å®“': 2132,\n",
       " '##ãƒ˜': 13693,\n",
       " '##é“¾': 20273,\n",
       " '##å“‚': 14559,\n",
       " '##çƒŸ': 17227,\n",
       " 'å’€': 1463,\n",
       " '##ç¼œ': 18417,\n",
       " 'é‡': 7022,\n",
       " 'æ¬–': 3611,\n",
       " 'ç¥¯': 4875,\n",
       " 'é€•': 6855,\n",
       " 'ç´ ': 5162,\n",
       " 'é†‹': 7005,\n",
       " 'crystal': 12070,\n",
       " 'ç¯': 4384,\n",
       " 'èŒ²': 5760,\n",
       " '626': 12463,\n",
       " 'but': 10288,\n",
       " '##å–§': 14659,\n",
       " 'èµ«': 6622,\n",
       " 'è´¹': 6589,\n",
       " 'â–²topsep': 10625,\n",
       " '##è€³': 18512,\n",
       " '364': 12673,\n",
       " 'ã€‰': 516,\n",
       " '##æ³„': 16843,\n",
       " 'é¨™': 7700,\n",
       " 'å…¸': 1073,\n",
       " '##ç ': 17829,\n",
       " 'å¢': 1306,\n",
       " 'å¼Ÿ': 2475,\n",
       " 'è†Š': 5600,\n",
       " '##å¸': 15419,\n",
       " 'åƒ': 1796,\n",
       " '##æ´™': 16877,\n",
       " '##å¨ƒ': 15072,\n",
       " 'test': 10060,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 ç´¢å¼•è½¬æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†è¯åºåˆ—è½¬æ¢ä¸ºidåºåˆ—\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['åƒ', 'è‘¡', 'è„', 'ä¸', 'å', 'è‘¡', 'è„', 'çš®', '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºtokenåºåˆ—\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'åƒ è‘¡ è„ ä¸ å è‘¡ è„ çš®!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†tokenåºåˆ—è½¬æ¢ä¸ºstring\n",
    "str_sen = tokenizer.convert_tokens_to_string(tokens)\n",
    "str_sen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  æ›´ä¾¿æ·çš„å®ç°æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106, 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºidåºåˆ—ï¼Œåˆç§°ä¹‹ä¸ºç¼–ç \n",
    "ids = tokenizer.encode(sen, add_special_tokens=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] åƒ è‘¡ è„ ä¸ å è‘¡ è„ çš®! [SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œåˆç§°ä¹‹ä¸ºè§£ç \n",
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False)\n",
    "str_sen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 å¡«å……ä¸æˆªæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106, 102, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¡«å……\n",
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1391, 5868, 5843, 102]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æˆªæ–­\n",
    "ids = tokenizer.encode(sen, max_length=5, truncation=True)\n",
    "ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 å…¶ä»–è¾“å…¥éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106, 102, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106, 102, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = [1 if idx != 0 else 0 for idx in ids]\n",
    "token_type_ids = [0] * len(ids)\n",
    "ids, attention_mask, token_type_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 å¿«é€Ÿè°ƒç”¨æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106, 102, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106, 102, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 å¤„ç†batchæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 102], [101, 679, 1391, 5868, 5843, 1168, 1402, 5868, 5843, 4649, 102], [101, 7556, 1232, 5445, 711, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens = [\"åƒè‘¡è„ä¸åè‘¡è„çš®\",\n",
    "        \"ä¸åƒè‘¡è„åˆ°åè‘¡è„çš®\",\n",
    "        \"é¡ºåŠ¿è€Œä¸º\"]\n",
    "res = tokenizer(sens)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.3 ms, sys: 0 ns, total: 45.3 ms\n",
      "Wall time: 44.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(1000):\n",
    "    tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 ms, sys: 15.6 ms, total: 43.2 ms\n",
      "Wall time: 7.68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = tokenizer([sen] * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast / Slow Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"åƒè‘¡è„ä¸åè‘¡è„çš®!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\", use_fast=False)\n",
    "slow_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 443 ms, sys: 0 ns, total: 443 ms\n",
      "Wall time: 442 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    fast_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 0 ns, total: 1.39 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªç¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    slow_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 323 ms, sys: 146 ms, total: 468 ms\n",
      "Wall time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = fast_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 15.8 ms, total: 1.12 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = slow_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1391, 5868, 5843, 679, 1402, 5868, 5843, 4649, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (0, 0)]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = fast_tokenizer(sen, return_offsets_mapping=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mslow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2858\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2857\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2858\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2964\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2945\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2946\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2961\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2962\u001b[0m     )\n\u001b[1;32m   2963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3037\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3028\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3029\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3030\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3035\u001b[0m )\n\u001b[0;32m-> 3037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils.py:711\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    706\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid. Should be a string, a list/tuple of strings or a list/tuple of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    713\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    715\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore information on available tokenizers at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    717\u001b[0m     )\n\u001b[1;32m    719\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    720\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674"
     ]
    }
   ],
   "source": [
    "inputs = slow_tokenizer(sen, return_offsets_mapping=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç‰¹æ®ŠTokenizerçš„åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8357a6f05b4345baaffbb95f34fed2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuyao\\miniconda3\\envs\\transformers\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yuyao\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccfd3477c5c45e894350699ab1fffc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)enization_chatglm.py:   0%|          | 0.00/17.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3ce5c1fcbb4d10b64c6b766cf99d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ice_text.model:   0%|          | 0.00/2.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChatGLMTokenizer(name_or_path='THUDM/chatglm-6b', vocab_size=130344, model_max_length=2048, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<sop>', 'eos_token': '<eop>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatglm_tokenizer\\\\tokenizer_config.json',\n",
       " 'chatglm_tokenizer\\\\special_tokens_map.json',\n",
       " 'chatglm_tokenizer\\\\ice_text.model',\n",
       " 'chatglm_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"chatglm_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"chatglm_tokenizer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
